{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import exp, sqrt, abs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE=0\n",
    "if CASE==0: dname=\"DATA\"\n",
    "if CASE==1: dname=\"DATA_b\"\n",
    "\n",
    "fname=dname+'/x_RBM_q0.1.dat'\n",
    "# loading data: each row is a list of visible units\n",
    "# NOTE: data \"x\" here is named \"v\" for \"visible\"\n",
    "v = np.loadtxt(fname, delimiter=\" \",dtype=int)\n",
    "# store in v0, because later we will shuffle v\n",
    "v0 = np.copy(v)\n",
    "# to start, take a small subsample\n",
    "# v = v[1:11]\n",
    "N = len(v)\n",
    "L = len(v[1])\n",
    "\n",
    "SPINS = True\n",
    "#SPINS = False\n",
    "\n",
    "if SPINS:\n",
    "    # sigmoid takes into account energy difference =2\n",
    "    GAP=2\n",
    "    # convert 0,1 -> -1,1\n",
    "    v = 2*v - 1\n",
    "    vmin=-1\n",
    "else:\n",
    "    GAP=1\n",
    "    vmin=0\n",
    "\n",
    "print(f'each of N={N} data has L={L} digits')\n",
    "\n",
    "for i in range(min(12,N)):\n",
    "    if SPINS: print(v0[i],\"\\n->\",v[i])\n",
    "    else: print(v[i])\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RBM, nr of hidden units\n",
    "if CASE==0: M = 3\n",
    "if CASE==1: M = 6\n",
    "# range of each initial weight\n",
    "sigma = sqrt(4. / float(L + M))\n",
    "# random seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "# initial weights from a Normal distr. (see literature, e.g. page 98 of Mehta's review)\n",
    "w = sigma * np.random.randn(L,M)\n",
    "a = sigma * np.random.randn(L)\n",
    "b = np.zeros(M)\n",
    "print(\"w=\",w);print(\"a=\",a);print(\"b=\",b)\n",
    "w0,a0,b0=np.copy(w),np.copy(a),np.copy(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coord(np,x0,f=1.0):\n",
    "    x=[x0] * np\n",
    "    print(x)\n",
    "    y=list(range(np))\n",
    "    for i in range(np):\n",
    "        y[i] = f*(y[i]/(np-1.) - 0.5)\n",
    "    return (x,y)\n",
    "(x1,y1)=create_coord(L,0)\n",
    "(x2,y2)=create_coord(M,1,f=0.7)\n",
    "\n",
    "def mycolor(val):\n",
    "    if val>0: return 'red'\n",
    "    elif val<0: return 'blue'\n",
    "    else: return 'black'\n",
    "\n",
    "def plotgraph_vert(epoch=0):\n",
    "    A=2./w.max()\n",
    "    for i in range(L):\n",
    "        for j in range(M):\n",
    "            ex, ey, col = (x1[i],x2[j]),(y1[i],y2[j]),mycolor(w[i][j])\n",
    "            plt.plot(ex, ey, col, zorder=1, lw=A*abs(w[i][j]))\n",
    "    # Scatter plot on top of lines\n",
    "    \n",
    "    A=300./(a.max()+b.max())\n",
    "    \n",
    "    for i in range(L):\n",
    "        plt.scatter(x1[i], y1[i], s=A*abs(a[i]), zorder=2, c=mycolor(a[i]))\n",
    "\n",
    "    for j in range(M):\n",
    "        plt.scatter(x2[j], y2[j], s=A*abs(b[j]), zorder=2, c=mycolor(b[j]), marker=\"s\")\n",
    "    plt.figaspect(1)\n",
    "    plt.title(f'>0 red, <0 blue, epoch={epoch}')\n",
    "    plt.show()\n",
    "    \n",
    "def plotgraph(epoch=0):\n",
    "    fig, ax = plt.subplots(1,1 , figsize=(10, 5))\n",
    "    ax.tick_params(left=False,bottom=False)\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    \n",
    "    A=1./max(w.max(),-w.min())\n",
    "    for i in range(L):\n",
    "        for j in range(M):\n",
    "            ex, ey, col = (y1[i],y2[j]),(x1[i],x2[j]),mycolor(w[i][j])\n",
    "            ax.plot(ex, ey, col, zorder=1, alpha=A*abs(w[i][j]))\n",
    "    # Scatter plot on top of lines\n",
    "    #A=300./(a.max()+b.max())\n",
    "    A=500.\n",
    "    for i in range(L):\n",
    "        ax.scatter(y1[i],x1[i], s=A*abs(a[i]), zorder=2, c=mycolor(a[i]))\n",
    "    for j in range(M):\n",
    "        ax.scatter(y2[j], x2[j], s=min(300,A*abs(b[j])), zorder=2, c=mycolor(b[j]), marker=\"s\")\n",
    "    ax.set_title(f'>0 red, <0 blue, epoch={epoch}')\n",
    "    ax.text(-0.5,0.9,\"hidden\\nlayer\")\n",
    "    plt.show()\n",
    "                  \n",
    "plotgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eq(213) page 97, activation via sigmoid\n",
    "# taking into account energy gap DE=2 for \"spin\" variables (-1,1)\n",
    "def activate(v_in,wei,bias,DE,info=False):\n",
    "    act = np.dot(v_in, wei) + bias\n",
    "    n = np.shape(act)\n",
    "    prob = 1. / (1. + exp(-DE*act))\n",
    "    v_out = np.full(n, vmin, dtype=int) # a list on -1's or 0's\n",
    "    v_out[np.random.random_sample(n) < prob] = 1 # activate the 1's with probability prob\n",
    "    if info:\n",
    "        print('input=', v_in)\n",
    "        print('act=',act)\n",
    "        print('prob=',prob)\n",
    "        print('output=',v_out)\n",
    "    return v_out\n",
    "\n",
    "k = 0\n",
    "activate(v[k],w,b,GAP,info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "plotgraph(0)\n",
    "\n",
    "# learning rate\n",
    "l_rate = 1.0\n",
    "\n",
    "# minibatch\n",
    "mini, m = 500, 0\n",
    "\n",
    "# train model\n",
    "print('===================================================')\n",
    "for epoch in range(100):\n",
    "    # aggregate normalization of batch statistics and learning rate\n",
    "    l_rate_m = l_rate / mini\n",
    "    for k in range(N):\n",
    "        if m==0:\n",
    "            # initialize averages in miniblock\n",
    "            v_data, v_model = np.zeros(L),np.zeros(L)\n",
    "            h_data, h_model = np.zeros(M),np.zeros(M)\n",
    "            vh_data,vh_model= np.zeros((L,M)),np.zeros((L,M))\n",
    "\n",
    "        # positive CD phase: generating h \n",
    "        h = activate(v[k],w,b,GAP)\n",
    "        # negative CD phase: generating fantasy vf\n",
    "        vf = activate(h,w.T,a,GAP)\n",
    "        # one more positive CD phase: generating fantasy h from fantasy vf \n",
    "        hf = activate(vf,w,b,GAP)\n",
    "\n",
    "        v_data  += v[k]\n",
    "        v_model += vf\n",
    "        h_data  += h\n",
    "        h_model += hf\n",
    "        vh_data += np.outer(v[k].T,h)\n",
    "        vh_model+= np.outer(vf.T,hf)\n",
    "    \n",
    "        m += 1\n",
    "        # minibatch\n",
    "        if m==mini:\n",
    "            # gradient of the likelihood: follow it along its positive direction\n",
    "            # with a \"vanilla\" SGD\n",
    "            dw = l_rate_m*(vh_data - vh_model)\n",
    "            da = l_rate_m*(v_data - v_model)\n",
    "            db = l_rate_m*(h_data - h_model)\n",
    "            if epoch<=1 and k<=mini:\n",
    "                print('----------- epoch =',epoch,'  k=',k,'  m=',m)\n",
    "                print('dw =',dw)\n",
    "                print('da =',da)\n",
    "                print('db =',db)\n",
    "            # basic step of vanilla gradient descent, from eq.(211)\n",
    "            w = w + dw\n",
    "            a = a + da\n",
    "            b = b + db\n",
    "            m=0\n",
    "    \n",
    "    # randomize the order of input data\n",
    "    np.random.shuffle(v)\n",
    "    # decrease the learning rate (here as a power law)\n",
    "    l_rate = l_rate / (0.01 * l_rate + 1)\n",
    "    if epoch%10==9:\n",
    "        plotgraph(epoch+1)\n",
    "        print('l_rate = ',l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('w0=',w0);print('a0=',a0);print('b0=',b0)\n",
    "print('w=',w);print('a=',a);print('b=',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html \n",
    "import pandas as pd\n",
    "\n",
    "ampl=40.\n",
    "\n",
    "# original, non-reshuffled data in v0\n",
    "v1 = np.zeros_like(v0)\n",
    "for k in range(N):\n",
    "    # positive CD phase: generating h \n",
    "    h = activate(v0[k],w,b,ampl*GAP)\n",
    "    # negative CD phase: generating fantasy vf with low T == large GAP\n",
    "    v1[k] = activate(h,w.T,a,ampl*GAP)\n",
    "# difference between fantasy and data\n",
    "diff = (v1 - v0)/2\n",
    "str0 = fname+'_M'+str(M)+'-mini'+str(mini)\n",
    "np.savetxt(str0+\".fantasy\", (v1+1)/2, fmt='%d',delimiter=' ')  \n",
    "np.savetxt(str0+'.diff', diff, fmt='%d',delimiter=' ')  \n",
    "\n",
    "\n",
    "def is_one(cell_value):\n",
    "    color0 = 'background-color: gray; color: white'\n",
    "    color1 = 'background-color: gold;'\n",
    "    if type(cell_value) in [float, int]:\n",
    "        if cell_value == 1:\n",
    "            return color1\n",
    "    return color0\n",
    "\n",
    "N1=12\n",
    "df0 = pd.DataFrame(v0[:N1])\n",
    "df1 = pd.DataFrame(((v1[:N1]-vmin)/(1-vmin)).astype(int))\n",
    "\n",
    "df0s = df0.style.set_table_attributes(\"style='display:inline'\")\n",
    "df1s = df1.style.set_table_attributes(\"style='display:inline'\")\n",
    "df0s.applymap(is_one)\n",
    "df1s.applymap(is_one)\n",
    "sty = [dict(selector=\"caption\",props=[(\"font-size\", \"150%\")])]\n",
    "df0s.set_caption('Original').set_table_styles(sty)\n",
    "df1s.set_caption('Denoised').set_table_styles(sty)\n",
    "\n",
    "display_html(df0s._repr_html_()+df1s._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
